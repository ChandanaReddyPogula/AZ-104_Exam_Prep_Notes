# Containers Overview

Containers are a lightweight virtualization technology that packages an application and its dependencies into a single, portable unit called an image. These images can be stored in repositories and run on any system with a container runtime.

---

## Key Concepts

| Concept                  | Description                                                                 |
|--------------------------|-----------------------------------------------------------------------------|
| **Container Image**      | A compressed package containing the application, dependencies, and OS services. |
| **Container Runtime**    | Software (e.g., Docker) that runs containers by downloading and extracting images. |
| **Isolation**            | Containers run in isolated environments but share the host OS kernel.        |
| **Lightweight OS**       | Containers use lightweight OS versions (e.g., Windows Server Core, Alpine Linux). |
| **Cross-Platform Limitation** | Linux containers cannot run on Windows hosts, and vice versa.          |

---

## Advantages of Containers

- **Resource Efficiency:**
  - Require fewer resources than VMs.
  - More containers can run on a single host compared to VMs.
- **Portability:**
  - Easily move applications between environments (e.g., on-premises to cloud).
- **Simplified Deployment:**
  - Consistent environments for development, testing, and production.
- **Scalability:**
  - Quickly scale applications using orchestration tools like Kubernetes.

---

## Popular Tools and Services

| Tool/Service                     | Description                                                                 |
|----------------------------------|-----------------------------------------------------------------------------|
| **Docker**                       | The most popular container runtime and image repository (Docker Hub).       |
| **Azure Container Instances (ACI)** | Serverless container service for running containers without managing VMs. |
| **Azure Kubernetes Service (AKS)** | Managed Kubernetes service for orchestrating containerized applications.  |

---

## Azure Container Services

### 1. Azure Container Instances (ACI)
- **Features:**
  - **Serverless:** No need to manage VMs.
  - **Quick deployment:** Simply point to a container image in a repository.
  - **Public access:** Access containers via a public IP or DNS name (e.g., `label.azure_region.azurecontainer.io`).
- **Use Case:** Ideal for simple, short-lived, or isolated workloads.

### 2. Azure Kubernetes Service (AKS)
- **Features:**
  - **Managed Kubernetes:** Simplifies deployment, scaling, and management of containerized applications.
  - **Automates complex tasks:** Microsoft handles the underlying infrastructure.
- **Use Case:** Ideal for large-scale, complex, and production-grade container workloads.

---

## Key Takeaways

- **Containers:**
  - Package applications and dependencies into portable images.
  - Share the host OS kernel, making them lightweight.
- **Docker:**
  - The most widely used container runtime and repository.
- **Azure Services:**
  - **ACI:** Serverless containers for quick, simple deployments.
  - **AKS:** Managed Kubernetes for scalable, complex workloads.

---

## Visual Representation

### Container Workflow
1. **Create Image:** Package application and dependencies.
2. **Store Image:** Upload to a repository (e.g., Docker Hub).
3. **Run Container:** Use a container runtime (e.g., Docker) to download and run the image.
4. **Orchestrate:** Use Kubernetes (e.g., AKS) for scaling and management.

### ACI vs. AKS

| Feature                     | Azure Container Instances (ACI)         | Azure Kubernetes Service (AKS)         |
|-----------------------------|-----------------------------------------|-----------------------------------------|
| **Management**              | Serverless (no VMs)                    | Managed Kubernetes                      |
| **Use Case**                | Simple, short-lived workloads          | Complex, scalable workloads             |
| **Access**                  | Public IP or DNS name                  | Advanced networking and scaling options |

---

# Azure Container Instances (ACI) Overview

ACI is a serverless container service that allows you to run containers without managing VMs. It’s ideal for simple, short-lived workloads.

---

## Key Features

| Feature              | Description                                                                 |
|----------------------|-----------------------------------------------------------------------------|
| **Serverless**       | No need to manage VMs or infrastructure.                                    |
| **Quick Deployment** | Deploy containers in seconds using CLI, PowerShell, or ARM templates.       |
| **Public Access**    | Access containers via a public IP or DNS name (e.g., `label.azure_region.azurecontainer.io`). |
| **Scaling**          | Scale out by creating additional containers (no auto-scaling built-in).     |

---

## Container Groups

### Definition:
The top-level object in ACI that represents all containers running on a host.

### Multi-Container Groups:
- Supported only for Linux containers.
- Containers in the same group share the same URL but use different ports.
- Requires an ARM template for deployment.

---

## Sizing and Scaling

### Default Configuration
- **CPU:** 1 core.
- **Memory:** 1.5 GB.

### Custom Sizing
- **Limits:**
  - Max image size: 15 GB.
  - Max resources per container: 4 CPU cores and 16 GB memory.
- **Process:**
  1. Delete the existing container.
  2. Deploy a new container with the desired size.

### Scaling Out
- Create additional containers manually or automate using Logic Apps.
- **Note:** ACI does not support auto-scaling natively.

---

## Key Takeaways

| Aspect                  | Details                                                                 |
|-------------------------|-------------------------------------------------------------------------|
| **Deployment**          | Use CLI, PowerShell, or ARM templates.                                 |
| **Access**              | Public IP or DNS name (e.g., `label.azure_region.azurecontainer.io`).  |
| **Multi-Container Groups** | Supported only for Linux containers.                                |
| **Sizing**              | Max 4 CPU cores, 16 GB memory, and 15 GB image size.                   |
| **Scaling**             | Scale out manually or automate with Logic Apps.                         |

---

## ACI Workflow
1. **Create Container:**
   - Specify image, resource group, and DNS name.
   - Deploy using CLI or PowerShell.
2. **Access Container:**
   - Use the public URL (e.g., `http://label.azure_region.azurecontainer.io`).
3. **Scale Out:**
   - Add more containers manually or automate with Logic Apps.

## ACI Limits

| Resource      | Limit                          |
|---------------|--------------------------------|
| **CPU**       | 1 core (default), up to 4 cores (max). |
| **Memory**    | 1.5 GB (default), up to 16 GB (max).   |
| **Image Size**| Max 15 GB.                     |

---

## Best Practices

- **Use Multi-Container Groups for Linux:**
  - Share resources and URLs efficiently.
- **Monitor Resource Usage:**
  - Ensure containers do not exceed CPU or memory limits.
- **Automate Scaling:**
  - Use Logic Apps to scale out based on specific conditions.

---

# Container Groups in ACI

A container group is the top-level object in ACI that hosts one or more containers. Containers within the same group share resources like CPU, memory, and network.

---

## Key Concepts

| Concept                  | Description                                                                 |
|--------------------------|-----------------------------------------------------------------------------|
| **Single Container Group** | Hosts one container (default for Windows containers).                     |
| **Multi-Container Group** | Hosts multiple containers (supported only for Linux containers).           |
| **Shared Resources**      | Containers in the same group share CPU, memory, and network resources.     |
| **Shared Network**        | Containers in the same group share the same IP address and DNS name label. |

---

## Updating Container Groups

You can update certain properties of a container group without deleting and recreating it. However, some properties require redeployment.

### 1. Updateable Properties
- **DNS Name Label:** Change the public URL for the container group.
- **Environment Variables:** Modify environment variables for the containers.
- **Restart Policy:** Update the restart behavior (e.g., Always, OnFailure, Never).

### 2. Non-Updateable Properties
- **Image:** Cannot change the container image.
- **Ports:** Cannot modify exposed ports.
- **Resource Limits:** Cannot change CPU or memory allocation.

---

## Key Takeaways

| Aspect                  | Details                                                                 |
|-------------------------|-------------------------------------------------------------------------|
| **Container Group**     | Hosts one or more containers (multi-container groups supported only for Linux). |
| **Shared Resources**    | CPU, memory, and network are shared within the group.                   |
| **Updateable Properties** | DNS name label, environment variables, restart policy.                |
| **Non-Updateable Properties** | Image, ports, CPU/memory limits.                                |
| **Update Process**      | Use the same create command with new properties; containers will restart. |

---

## Container Group Workflow
1. **Create Container Group:**
   - Specify image, DNS name, and resource limits.
2. **Update Container Group:**
   - Modify updateable properties (e.g., DNS name).
   - Containers restart automatically.
3. **Non-Updateable Changes:**
   - Delete and recreate the container group.

---

## Best Practices

- **Plan Ahead:**
  - Set DNS names and resource limits carefully, as they cannot be updated.
- **Use Multi-Container Groups for Linux:**
  - Share resources efficiently for related containers.
- **Test Updates:**
  - Verify that updates do not disrupt application functionality.
 
---

# Azure Kubernetes Service (AKS) Overview

AKS is a managed Kubernetes service that simplifies the deployment, scaling, and management of containerized applications. It uses pods to run containers and provides storage options for persistent and non-persistent data.

---

## Key Concepts

| Concept                  | Description                                                                 |
|--------------------------|-----------------------------------------------------------------------------|
| **Cluster**              | A group of nodes (servers) running Kubernetes.                              |
| **Control Plane**        | The master node responsible for managing the cluster.                       |
| **Node**                 | A worker machine in the cluster that runs pods.                             |
| **Pod**                  | The smallest deployable unit in Kubernetes, which can run one or more containers. |
| **Persistent Volume (PV)** | Storage that exists independently of pods, ensuring data persistence.     |
| **Persistent Volume Claim (PVC)** | A request for storage by a pod, specifying size, type, and tier.      |

---

## Storage Options in AKS

### 1. Azure Disks
- **Use Case:** Block storage for single-pod access.
- **Features:**
  - High performance.
  - Supports **ReadWriteOnce (RWO)** access mode.

### 2. Azure Files
- **Use Case:** File storage for multi-pod access.
- **Features:**
  - Supports **Server Message Block (SMB)** protocol.
  - Allows **ReadWriteMany (RWX)** access mode.
- **Use Case:** Shared storage across multiple pods.

### 3. Persistent Volumes (PV)
- **Use Case:** Persistent storage that survives pod deletion.
- **Features:**
  - Created by cluster administrators or Kubernetes API.
  - Backed by Azure Disks or Azure Files.
- **Persistent Volume Claim (PVC):**
  - A request for storage by a pod.
  - Specifies size, type, and tier.

---

## Key Takeaways

| Storage Type             | Use Case                  | Access Mode               | Persistence |
|--------------------------|---------------------------|---------------------------|-------------|
| **Azure Disks**          | Single-pod storage        | ReadWriteOnce (RWO)       | Non-persistent |
| **Azure Files**          | Multi-pod storage         | ReadWriteMany (RWX)       | Non-persistent |
| **Persistent Volumes (PV)** | Persistent storage for pods | Depends on backend      | Persistent  |

---

## Visual Representation

### Storage Workflow in AKS
1. **Create Storage:**
   - Use **Azure Disks** for single-pod storage.
   - Use **Azure Files** for multi-pod storage.
2. **Persistent Storage:**
   - Create a **Persistent Volume (PV)**.
   - Bind it to a pod using a **Persistent Volume Claim (PVC)**.
3. **Access Storage:**
   - Pods access storage via PVCs.
   - Data persists even if pods are rescheduled or deleted.

### Storage Options

| Option                  | Single-Pod Access | Multi-Pod Access | Persistence |
|-------------------------|-------------------|------------------|-------------|
| **Azure Disks**         | Yes               | No               | No          |
| **Azure Files**         | No                | Yes              | No          |
| **Persistent Volumes**  | Yes               | Yes              | Yes         |

---

## Best Practices

- **Use Persistent Volumes for Critical Data:**
  - Ensure data persistence across pod rescheduling or deletion.
- **Choose the Right Storage Type:**
  - Use **Azure Disks** for high-performance, single-pod storage.
  - Use **Azure Files** for shared storage across multiple pods.
- **Automate Storage Provisioning:**
  - Use PVCs to dynamically provision storage based on pod requirements.
 
---

# Scaling in AKS

AKS provides flexible scaling options to handle varying workloads. You can scale pods (application instances) and nodes (underlying VMs) either manually or automatically.

---

## Key Scaling Concepts

| Scaling Type         | Description                                                                 |
|----------------------|-----------------------------------------------------------------------------|
| **Pod Scaling**      | Adjust the number of pods running your application.                         |
| **Node Scaling**     | Adjust the number of nodes (VMs) in the AKS cluster.                        |
| **Manual Scaling**   | Manually set the number of pods or nodes.                                   |
| **Automatic Scaling**| Automatically adjust pods or nodes based on metrics like CPU usage.         |

---

## Manual Scaling

### 1. Scaling Pods
- **Tool:** Use `kubectl` (Kubernetes command-line tool).
- **Steps:**
  1. Install `kubectl` using the command: `az aks install-cli`.
  2. Authenticate to the AKS cluster using: `az aks get-credentials --resource-group aks_rg --name aks_cluster`.
  3. Scale pods using: `kubectl scale --replicas=3 deployment/az104`.

### 2. Scaling Nodes
- **Tool:** Use Azure CLI or PowerShell.
- **Azure CLI:** Use the command: `az aks scale --resource-group aks_rg --name aks_cluster --node-count 3`.
- **PowerShell:** Use the command: `Get-AzAksCluster -ResourceGroupName aks_rg -Name aks_cluster | Set-AzAksCluster -NodeCount 3`.

---

## Automatic Scaling

### 1. Horizontal Pod Autoscaler (HPA)
- **What It Does:** Automatically scales the number of pods based on CPU or memory usage.
- **Command:** Use `kubectl autoscale deployment az104 --cpu-percent=60 --max=5 --min=2` to set the CPU threshold to 60%, with a minimum of 2 pods and a maximum of 5 pods.

### 2. Cluster Autoscaler
- **What It Does:** Automatically scales the number of nodes in the cluster based on pod resource requirements.
- **Command:** Use `az aks update --resource-group aks_rg --name aks_cluster --enable-cluster-autoscaler --max-count 5 --min-count 1` to set a minimum of 1 node and a maximum of 5 nodes.

---

## Key Takeaways

| Scaling Type         | Tool/Command                          | Use Case                                  |
|----------------------|---------------------------------------|------------------------------------------|
| **Manual Pod Scaling** | `kubectl scale`                      | Adjust pod count manually.               |
| **Manual Node Scaling** | `az aks scale` or `Set-AzAksCluster` | Adjust node count manually.              |
| **Automatic Pod Scaling** | `kubectl autoscale` (HPA)           | Scale pods based on CPU/memory usage.    |
| **Automatic Node Scaling** | `az aks update` (Cluster Autoscaler) | Scale nodes based on pod resource needs. |

---

## Visual Representation

### Scaling Workflow
1. **Manual Scaling:**
   - Use `kubectl` for pods.
   - Use Azure CLI/PowerShell for nodes.
2. **Automatic Scaling:**
   - Use HPA for pods.
   - Use Cluster Autoscaler for nodes.

### Scaling Options

| Scaling Type         | Manual                          | Automatic                          |
|----------------------|---------------------------------|------------------------------------|
| **Pods**             | `kubectl scale`                | HPA (`kubectl autoscale`)          |
| **Nodes**            | `az aks scale` or `Set-AzAksCluster` | Cluster Autoscaler (`az aks update`) |

---

## Best Practices

- **Use Automatic Scaling for Dynamic Workloads:**
  - HPA for pods and Cluster Autoscaler for nodes.
- **Set Appropriate Limits:**
  - Define min/max values for pods and nodes to avoid over-provisioning.
- **Monitor Metrics:**
  - Use Azure Monitor or Kubernetes Dashboard to track CPU/memory usage.
 
---

# Networking in AKS

AKS supports two networking models: **kubenet (basic)** and **Azure CNI (advanced)**. Both models handle IP addressing for nodes and pods differently, and Kubernetes uses services and ingress controllers to manage network traffic.

---

## Key Networking Models

| Model               | Description                                                                 |
|---------------------|-----------------------------------------------------------------------------|
| **Kubenet (Basic)** | - Nodes get IPs from the VNet subnet.                                       |
|                     | - Pods get internal IPs from a separate address space.                      |
|                     | - Requires NAT for external communication.                                  |
| **Azure CNI (Advanced)** | - Both nodes and pods get IPs from the VNet subnet.                     |
|                     | - No NAT required; pods can communicate directly with other Azure resources. |

---

## Kubernetes Services

Services provide a stable IP address for pods, which are ephemeral and frequently change IPs. They act as a load balancer for incoming traffic.

### Service Types

| Type              | Description                                                                 |
|-------------------|-----------------------------------------------------------------------------|
| **ClusterIP**     | Provides an internal IP for communication within the cluster.               |
| **NodePort**      | Maps a port on the node to the service, allowing external access.           |
| **LoadBalancer**  | Creates an Azure Load Balancer with an external IP for public access.       |
| **ExternalName**  | Maps a service to a DNS name.                                               |

---

## Ingress Controllers

Ingress controllers provide advanced traffic routing based on URLs, paths, or other rules. They are used when LoadBalancer services are insufficient.

### Ingress Options

| Option                              | Description                                                                 |
|-------------------------------------|-----------------------------------------------------------------------------|
| **NGINX**                           | A popular open-source ingress controller.                                   |
| **HTTP Application Routing**        | AKS feature for simple HTTP routing.                                        |
| **Application Gateway Ingress Controller (AGIC)** | Uses Azure Application Gateway for advanced traffic management.       |

---

## Key Takeaways

### Networking Models

| Aspect              | Kubenet                                      | Azure CNI                                   |
|---------------------|----------------------------------------------|--------------------------------------------|
| **IP Addressing**   | Nodes: VNet subnet; Pods: Internal address space. | Nodes and Pods: VNet subnet.               |
| **NAT Requirement** | Required for external communication.         | Not required.                              |
| **Direct Pod Access** | Not possible.                              | Possible.                                  |

### Service Types

| Type              | Use Case                                                                 |
|-------------------|-------------------------------------------------------------------------|
| **ClusterIP**     | Internal communication within the cluster.                              |
| **NodePort**      | External access via node port mapping.                                  |
| **LoadBalancer**  | Public access with Azure Load Balancer.                                 |
| **ExternalName**  | DNS-based service mapping.                                              |

### Ingress Controller

| Option                              | Use Case                                                                 |
|-------------------------------------|-------------------------------------------------------------------------|
| **NGINX**                           | Advanced traffic routing.                                               |
| **HTTP Application Routing**        | Simple HTTP routing.                                                    |
| **AGIC**                            | Advanced traffic management with Azure Application Gateway.              |

---

### Networking Workflow
1. **Choose Networking Model:**
   - **Kubenet:** Nodes and pods use separate IP spaces.
   - **Azure CNI:** Nodes and pods share the VNet subnet.
2. **Deploy Services:**
   - Use **ClusterIP** for internal communication.
   - Use **LoadBalancer** for public access.
3. **Advanced Routing:**
   - Use **Ingress Controllers** (e.g., NGINX, AGIC) for URL/path-based routing.

### Service vs. Ingress

| Feature              | Service                          | Ingress                          |
|----------------------|----------------------------------|----------------------------------|
| **Traffic Routing**  | Basic load balancing.            | Advanced routing (e.g., URL/path-based). |
| **Use Case**         | Simple internal/external access. | Complex traffic management.      |

---

## Best Practices

- **Choose the Right Networking Model:**
  - Use **kubenet** for simplicity and fewer IP addresses.
  - Use **Azure CNI** for direct pod communication and no NAT.
- **Use Services for Stable IPs:**
  - Ensure pods remain accessible despite IP changes.
- **Leverage Ingress Controllers:**
  - Use **NGINX** or **AGIC** for advanced traffic routing.
 
---

# Upgrading an AKS Cluster

Upgrading an AKS cluster ensures access to new features, bug fixes, and security patches. The process involves checking for available upgrades and applying them in a controlled manner to avoid downtime.

---

## Key Steps for Upgrading AKS

### Check for Available Upgrades:
- Use the Azure CLI command: `az aks get-upgrades --resource-group aks_rg --name aks_cluster`.
- The output (in JSON) shows available Kubernetes versions under the `upgrades` section.

### Upgrade the Cluster:
- Use the Azure CLI command: `az aks upgrade --resource-group aks_rg --name aks_cluster --kubernetes-version 1.21.1`.
- Replace `1.21.1` with the desired Kubernetes version.

---

## Upgrade Process

### Node-by-Node Upgrade:
- AKS upgrades one node at a time to ensure application availability.
- **Steps:**
  1. **Cordon the Node:** Stop scheduling new pods on the node.
  2. **Drain the Node:** Move running pods to other nodes.
  3. **Create a New Node:** Spin up a new node with the upgraded Kubernetes version.
  4. **Delete the Old Node:** Remove the node running the older version.
- Repeat the process for all nodes in the cluster.

### Version Skipping:
- Cannot skip minor versions. For example:
  - To upgrade from `1.19.3` to `1.21.1`, you must first upgrade to `1.20.x`.

---

## Key Takeaways

| Step                  | Command/Tool            | Description                                                                 |
|-----------------------|-------------------------|-----------------------------------------------------------------------------|
| **Check Upgrades**    | `az aks get-upgrades`   | Lists available Kubernetes versions.                                        |
| **Upgrade Cluster**   | `az aks upgrade`        | Upgrades the cluster to the specified version.                              |
| **Node-by-Node Upgrade** | Automated by AKS     | Ensures minimal disruption during upgrades.                                 |
| **Version Skipping**  | Not allowed             | Must upgrade sequentially through minor versions.                           |

---

### Upgrade Workflow
1. **Check for Upgrades:**
   - Use `az aks get-upgrades` to list available versions.
2. **Initiate Upgrade:**
   - Use `az aks upgrade` to start the upgrade process.
3. **Node-by-Node Process:**
   - Cordon → Drain → Create New Node → Delete Old Node.
4. **Repeat:**
   - Continue until all nodes are upgraded.

### Version Upgrade Path

| Current Version | Upgrade Path                  |
|-----------------|-------------------------------|
| 1.19.3          | 1.19.3 → 1.20.x → 1.21.1      |
| 1.20.5          | 1.20.5 → 1.21.1               |

---

## Best Practices

- **Plan Upgrades:**
  - Regularly check for new Kubernetes versions.
  - Test upgrades in a non-production environment first.
- **Avoid Skipping Versions:**
  - Follow the sequential upgrade path (e.g., 1.19 → 1.20 → 1.21).
- **Monitor During Upgrades:**
  - Use Azure Monitor or Kubernetes Dashboard to track the upgrade process.
 
  ---
