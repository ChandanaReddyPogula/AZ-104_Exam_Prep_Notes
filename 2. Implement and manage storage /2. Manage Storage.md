# 1. Azure Import/Export Service

## 1. Overview
- **Purpose**: Physically ship data to/from Azure Storage when:
  - Large datasets make internet upload/download impractical.
  - Limited/no internet connectivity is available.
- **Supported Services**:
  - **Blob Storage**: Import/export blobs.
  - **Azure Files**: Import/export file shares.

## 2. Key Features

| **Feature**               | **Description**                                                                 |
|---------------------------|---------------------------------------------------------------------------------|
| **Import Jobs**            | Ship data from on-premises to Azure Storage.                                    |
| **Export Jobs**            | Ship data from Azure Storage to on-premises.                                    |
| **Data Transfer**          | Use physical disks (HDDs/SSDs) for data transfer.                               |
| **BitLocker Encryption**   | Disks are encrypted with BitLocker for security.                                |

## 3. Steps to Create an Export Job
1. **Log in to Azure Portal**:
   - Go to **All Services > Import/Export Jobs**.
2. **Create Export Job**:
   - Click **Create Import/Export Job**.
3. **Basics Tab**:
   - Choose **Export From Azure**.
   - Specify **Job Name** and **Resource Group**.
4. **Job Details Tab**:
   - Select the **Storage Account**.
   - Choose blobs to export:
     - **Export All**: Export all blobs.
     - **Selected Containers and Blobs**: Export specific containers/blobs.
     - **Export From Blob List File**: Use an XML file to specify blobs.
5. **Return Shipping Info Tab**:
   - Provide **Carrier Information** and **Shipping Address**.
6. **Summary Tab**:
   - Review and confirm the job.

## 4. After Receiving Disks
- **Retrieve BitLocker Keys**:
  - Go to the **Import/Export Job** in the Azure portal.
  - Use the keys to unlock the disks.

---

# 2. Create an Import Job

## 1. Overview
- **Purpose**: Import large volumes of data into Azure by shipping physical disks to Microsoft.
- **Supported Services**:
  - **Blob Storage**: Import block, page, and append blobs.
  - **Azure Files**: Import file shares (only for import jobs).

## 2. Key Tools and Requirements

| **Tool/Requirement**       | **Description**                                                                 |
|----------------------------|---------------------------------------------------------------------------------|
| **WAImportExport Tool**    | - **Version 1**: For Blob Storage.                                              |
|                            | - **Version 2**: For Azure Files.                                               |
| **Operating System**       | Windows 7, Windows Server 2008 R2, or later (64-bit only).                      |
| **Dependencies**           | .NET Framework 4.5.1 or later, BitLocker.                                       |
| **Supported Disks**        | - **SSD**: 2.5" SATA III.                                                       |
|                            | - **HDD**: 2.5" or 3.5" SATA II/III.                                            |
|                            | - **External HDDs**: USB adapters only.                                         |
| **Disk Limits**            | Max 10 disks per job (mix of HDDs and SSDs allowed).                            |

## 3. Steps to Create an Import Job

### **Prepare Drives**:
1. Use the **WAImportExport Tool** to copy data to disks.
2. Example command (Version 1):
   ```cmd
   WAImportExport.exe PrepImport /j:<JournalFile> /id:<SessionId> /logdir:<LogDirectory> /sk:<StorageAccountKey> /InitialDriveSet:<driveset> /DataSet:<driveset>
   ```
3. The **WAImportExport Tool** creates a **journal file** for each drive, mapping files to Azure Storage.

### **Create Import Job in Azure Portal**:
1. Go to **All Services > Storage > Import/Export Jobs**.
2. Click **Create Import/Export Job**.
3. **Basics Tab**:
   - Choose **Import Into Azure**.
   - Specify **Job Name** and **Resource Group**.
4. **Job Details Tab**:
   - Upload the **journal file**.
   - Select the destination **storage account**.
5. **Return Shipping Info Tab**:
   - Provide **carrier information** and **return address**.
6. **Summary Tab**:
   - Confirm and create the job.

### **Ship Disks to Microsoft**:
- Use a supported courier service with a **tracking number**.
- Update the job properties in Azure with the tracking number.

### **Monitor Job Status**:
- Check the job status in Azure until it is completed.
- Verify data upload in Azure Storage.

---

# 3. Azure Storage Explorer

## 1. Overview
- **Purpose**: A cross-platform tool to manage Azure Storage accounts and services.
- **Supported Services**:
  - **Azure Storage**: Blob, Table, Queue, and File Storage.
  - **Other Services**: Cosmos DB and Azure Data Lake Storage.
- **Platforms**: Windows, macOS, Linux, and integrated into the Azure Portal.

## 2. Installation
- **Download**: Available at [Azure Storage Explorer](https://azure.microsoft.com/features/storage-explorer/).
- **Azure Portal Integration**: Access via **Storage Explorer (Preview)** in the storage account blade.

## 3. Connecting to Storage Accounts

| **Connection Method**               | **Description**                                                                 |
|-------------------------------------|---------------------------------------------------------------------------------|
| **Add An Azure Account**            | Sign in with a work or Microsoft account to access all storage accounts via RBAC.|
| **Using A Connection String**       | Use the storage accountâ€™s connection string (found under Access Keys).           |
| **Use A Shared Access Signature (SAS) URI** | Use an SAS token for restricted access (e.g., read-only for a limited time).     |
| **Using A Storage Account Name And Key** | Use the storage account name and key (found under Access Keys).                 |
| **Attach To A Local Emulator**      | Connect to the local Azure Storage emulator (part of the Azure SDK).             |

## 4. Key Features and Operations

| **Storage Service** | **Supported Operations**                                                                 |
|---------------------|-----------------------------------------------------------------------------------------|
| **Blob Storage**    | - **Containers**: Create, rename, copy, delete, manage access levels, leases, SAS.     |
|                     | - **Blobs**: Upload, download, manage folders, rename, delete, copy, create snapshots, change access tier, manage SAS. |
| **Table Storage**   | - **Tables**: Create, rename, copy, delete, manage SAS.                                |
|                     | - **Entities**: Import, export, view, add, edit, delete, query.                        |
| **Queue Storage**   | - **Queues**: Create, delete, manage SAS.                                               |
|                     | - **Messages**: Add, view, dequeue, clear.                                              |
| **File Storage**    | - **File Shares**: Create, rename, copy, delete, create snapshots, connect to VMs, manage SAS. |
|                     | - **Files**: Upload, download, manage folders, copy, rename, delete.                     |

## 5. Copying Blobs Between Storage Accounts
1. **Select Source Blob**:
   - Navigate to the source storage account and select the blob(s).
   - Click **Copy** on the toolbar.
2. **Paste to Destination**:
   - Navigate to the destination storage account and container.
   - Click **Paste** on the toolbar.

## 6. Key Points for Exam
- **Connection Methods**:
  - Use **SAS URI** for restricted access.
  - Use **Storage Account Name and Key** for full access.
- **Supported Services**:
  - Works with **Blob, Table, Queue, and File Storage**.
  - Also supports **Cosmos DB** and **Azure Data Lake Storage**.
- **Blob Copy**:
  - Use the **Copy** and **Paste** features to transfer blobs between storage accounts.
 
---

# 4. Copy Data Using AzCopy

## 1. Overview
- **Purpose**: A command-line utility for bulk data transfer to/from Azure Storage.
- **Key Features**:
  - **Asynchronous Operations**: Runs multiple operations simultaneously.
  - **Fault-Tolerant**: Resumes interrupted transfers.
  - **Incremental Backups**: Syncs and backs up blobs incrementally.
  - **Platforms**: Windows, Linux, macOS.

## 2. Authentication Methods

| **Method**               | **Description**                                                                 |
|--------------------------|---------------------------------------------------------------------------------|
| **Azure AD Login**        | Use `azcopy login` to authenticate with Azure AD credentials.                   |
| **Service Principal**     | Use `--service-principal` with application ID and tenant ID.                    |
| **SAS Token**             | Use SAS tokens for restricted access.                                           |
| **Access Key**            | Use storage account access keys for full access.                                |
| **Managed Identity**      | Use managed identities for Azure resources.                                     |

## 3. Key Commands

| **Command**              | **Description**                                                                 |
|--------------------------|---------------------------------------------------------------------------------|
| **Upload Data**           | Copy data from local to Azure Blob Storage.                                     |
| **Download Data**         | Copy data from Azure Blob Storage to local.                                     |
| **Async Blob Copy**       | Copy blobs between storage accounts asynchronously.                             |
| **Sync Blob Copy**        | Synchronize blobs between containers (incremental copy).                        |

## 4. Examples

### **Upload a File**:
```bash
azcopy copy "CreateUserTemplate.csv" "https://examref.blob.core.windows.net/destcontainer/"
```
### **With SAS Token**:
```bash
azcopy copy "CreateUserTemplate.csv" "https://examref.blob.core.windows.net/destcontainer/?<sas-token>"
```
### **Upload Multiple Files (Recursive)**:
```bash
azcopy copy "C:\data\*" "https://examref.blob.core.windows.net/destcontainer/?<sas-token>" --recursive=true
```
### **Download a File**:
```bash
azcopy copy "https://examref.blob.core.windows.net/srccontainer/CreateUserTemplate.csv" "C:\downloads\"
```
### **Async Blob Copy**:
```bash
azcopy copy "https://examref.blob.core.windows.net/srccontainer/[blob-path]?<sas-token>" "https://examrefdest.blob.core.windows.net/destcontainer/[blob-path]?<sas-token>"
```
### **Sync Blob Copy**:
```bash
azcopy sync "https://examref.blob.core.windows.net/srccontainer/?<sas-token>" "https://examref.blob.core.windows.net/destcontainer/"
```
### **Delete Unmatched Blobs**:
```bash
azcopy sync "https://examref.blob.core.windows.net/srccontainer/?<sas-token>" "https://examref.blob.core.windows.net/destcontainer/" --delete-destination=true
```

## 5. Key Points for Exam
- **Authentication**:
  - Use **SAS Tokens** for restricted access.
  - Use **Service Principals** for automated scripts.
- **Commands**:
  - Use `azcopy copy` for upload/download.
  - Use `azcopy sync` for incremental backups and synchronization.
- **Fault Tolerance**:
  - AzCopy resumes interrupted transfers automatically.
- **Recursive Option**:
  - Use `--recursive=true` to copy folders and subdirectories.

---

# 5. Azure Storage Replication

## 1. Overview
- **Purpose**: Ensures data durability and high availability by replicating data across multiple locations.
- **Replication Options**:
  - **LRS (Locally Redundant Storage)**: 3 copies within a single datacenter.
  - **ZRS (Zone Redundant Storage)**: 3 copies across availability zones in a region.
  - **GRS (Geo-Redundant Storage)**: 6 copies (3 local + 3 in a secondary region).
  - **RA-GRS (Read-Access GRS)**: GRS + read-only access to the secondary region.
  - **GZRS (Geo-Zone Redundant Storage)**: ZRS + 3 copies in a secondary region.
  - **RA-GZRS (Read-Access GZRS)**: GZRS + read-only access to the secondary region.

## 2. Replication Scenarios and Availability

| **Scenario**                  | **LRS**         | **ZRS**         | **GRS**         | **RA-GRS**      | **GZRS**        | **RA-GZRS**     |
|-------------------------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| **Server/Datacenter Failure** | Available       | Available       | Available       | Available       | Available       | Available       |
| **Entire Datacenter Failure** | Not Available   | Available       | Available       | Available       | Available       | Available       |
| **Region-Wide Failure**       | Not Available   | Not Available   | Microsoft-Controlled Failover | Read-Only Until Failover | Microsoft-Controlled Failover | Read-Only Until Failover |
| **Durability**                | 99.999999999%   | 99.9999999999%  | 99.999999999999%| 99.999999999999%| 99.999999999999%| 99.999999999999%|
| **Read Availability SLA**     | 99.9%           | 99.9%           | 99.9%           | 99.99%          | 99.99%          | 99.99%          |
| **Write Availability SLA**    | 99.9%           | 99.9%           | 99.9%           | 99.9%           | 99.9%           | 99.9%           |

## 3. Changing Replication Mode
- **LRS, GRS, RA-GRS**: Can be changed freely; data is replicated asynchronously.
- **ZRS, GZRS, RA-GZRS**:
  - **Recommended**: Copy data to a new storage account with the desired replication mode (may require downtime).
  - **Alternative**: Request live migration via Azure Support.

## 4. Blob Object Replication
- **Purpose**: Asynchronously replicates block blobs between storage accounts.
- **Requirements**:
  - **Blob Versioning**: Enabled on both source and destination accounts.
  - **Blob Change Feed**: Enabled on the source account.
- **Benefits**:
  - Distribute data across regions for low-latency access.
  - Reduce compute costs by processing data in one region and replicating results.
  - Archive replicated data using Lifecycle Management policies.
- **Limitations**:
  - Does not support Archive tier, blob snapshots, or immutable blobs.
  - Maximum of 2 destination accounts per source account.
  - Destination container becomes read-only after replication policy is created.

## 5. Configuring Blob Object Replication
1. **Enable Prerequisites**:
   - Enable **Blob Versioning** and **Blob Change Feed** on the source and destination accounts.
2. **Set Up Replication Rules**:
   - Go to **Storage Account > Blob Service > Object Replication > Set Up Replication Rules**.
   - Define up to 10 rules per policy.
3. **Configure Rules**:
   - Select **Source Container** and **Destination Container**.
   - Use **Prefix Filters** to limit replication scope.
4. **Choose Copy Over Option**:
   - **Everything**: Copy all matching blobs.
   - **Only New Objects**: Copy only new blobs.
   - **Custom**: Specify a date/time for copying blobs.
5. **Monitor Replication**:
   - Check replication status in the **Object Replication** blade.
   - View replication details for individual blobs.

## 6. Key Points for Exam
- **Replication Options**:
  - Use **LRS** for single-region redundancy.
  - Use **GRS/GZRS** for cross-region redundancy.
- **Blob Object Replication**:
  - Requires **Blob Versioning** and **Blob Change Feed**.
  - Destination container becomes read-only after replication.
- **Limitations**:
  - No support for Archive tier, snapshots, or immutable blobs.
  - Maximum of 2 destination accounts per source account.
 
---
